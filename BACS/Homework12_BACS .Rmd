---
title: "Homework12_BACS"
author: "109090035 helped by 109070022,109060082,109070028"
date: "5/3/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      comment = "", 
                      dev.args = list(                                       pointsize = 11))
library(FSA)
library(car)
library(skimr)
library(psych)
library(kableExtra)
library(tidyverse)
library(dplyr)
library(magrittr)
library(Ecdat)
library(gapminder)
library(nycflights13)

ptable = function(df,digits = getOption("digits"),size = 14){
  df %>% knitr::kable(digits = digits) %>% 
    kable_classic(lightable_options = c("striped", "hover", "condensed"),
                  fixed_thead = list(enabled = T, 
                                     background = "lavender"),
                  font_size = size, full_width = F,
                  html_font = "helvetica")
}
```


### Create a data.frame called cars_log with log-transformed columns for mpg, weight, and acceleration (model_year and origin don’t have to be transformed)

```{r}
# load the car dataset 
cars <- read.table("/Users/user/Downloads/auto-data.txt", header=FALSE, na.strings = "?")

names(cars) <- c("mpg", "cylinders", "displacement", "horsepower", "weight", "acceleration", "model_year", "origin")

# Remove unnecessary columns (displacement, horsepower, and NA)
cars <- subset(cars, select = -c(displacement, horsepower))

# Create cars_log data frame with log-transformed columns
cars_log <- cars
cars_log$mpg <- log(cars$mpg)
cars_log$weight <- log(cars$weight)
cars_log$acceleration <- log(cars$acceleration)

# Print cars_log data frame
head(cars_log)
```

### Question 1) Let’s visualize how weight and acceleration are related to mpg.

### a. Let’s visualize how weight might moderate the relationship between acceleration and mpg:

### i. Create two subsets of your data, one for light-weight cars (less than mean weight) and one for heavy cars (higher than the mean weight) HINT: consider carefully how you compare log weights to mean weight
### ii. Create a single scatter plot of acceleration vs. mpg, with different colors and/or shapes for light versus heavy cars

```{r}
# Calculate the mean weight of the original cars dataset
mean_weight <- mean(cars$weight)

# Create two subsets of cars_log data, one for light-weight cars and one for heavy cars
light_cars <- subset(cars_log, weight < log(mean_weight))
heavy_cars <- subset(cars_log, weight >= log(mean_weight))


# Create a scatter plot of acceleration vs. mpg for light-weight and heavy cars
ggplot() +
  geom_point(data = light_cars, aes(x = acceleration, y = mpg, color = "Light-weight cars")) +
  geom_point(data = heavy_cars, aes(x = acceleration, y = mpg, color = "Heavy cars")) +
  labs(title = "Acceleration vs. MPG for Light-weight and Heavy Cars",
       x = "Log(Acceleration)",
       y = "Log(MPG)",
       color = "Car Weight") +
  theme_minimal()

```

### iii. Draw two slopes of acceleration-vs-mpg over the scatter plot:  one slope for light cars and one slope for heavy cars (distinguish them by appearance)## R Markdown

```{r}
# Add a weight_category column to cars_log dataset
cars_log$weight_category <- ifelse(cars_log$weight < log(mean_weight), "Light-weight cars", "Heavy cars")

# Create a scatter plot of acceleration vs. mpg with different colors for light and heavy cars
plot <- ggplot(data = cars_log, aes(x = acceleration, y = mpg, color = weight_category)) +
  geom_point() +
  labs(title = "Acceleration vs. MPG for Light-weight and Heavy Cars",
       x = "Log(Acceleration)",
       y = "Log(MPG)",
       color = "Car Weight") +
  theme_minimal()

# Add two slopes for light-weight and heavy cars
plot_with_slopes <- plot +
  geom_smooth(data = subset(cars_log, weight_category == "Light-weight cars"),
              aes(x = acceleration, y = mpg, color = weight_category),
              method = "lm", se = FALSE, linetype = "solid") +
  geom_smooth(data = subset(cars_log, weight_category == "Heavy cars"),
              aes(x = acceleration, y = mpg, color = weight_category),
              method = "lm", se = FALSE, linetype = "solid")

# Display the plot
plot_with_slopes

```

### b. Report the full summaries of two separate regressions for light and heavy cars where log.mpg. is dependent on log.weight., log.acceleration., model_year and origin

```{r}
# Perform separate linear regressions for light and heavy cars
light_cars_regression <- lm(mpg ~ weight + acceleration + model_year + origin, data = light_cars)
heavy_cars_regression <- lm(mpg ~ weight + acceleration + model_year + origin, data = heavy_cars)

# Display full summaries of the linear regressions
summary(light_cars_regression)
summary(heavy_cars_regression)

```

### c. (not graded) Using your intuition only: What do you observe about light versus heavy cars so far?

Based on the regression results, the following observations can be made about light versus heavy cars:

1. In both models, the `weight` variable has a significant negative effect on `mpg`. This indicates that as the weight of the cars increases, the fuel efficiency (mpg) decreases. The effect is stronger for light cars (-0.8499) compared to heavy cars (-0.8224), meaning that an increase in weight has a more significant impact on the mpg of lighter cars.

2. The `model_year` variable also has a significant positive effect on `mpg` in both models. This suggests that more recent car models tend to have better fuel efficiency (mpg). The effect is stronger for light cars (0.0329) compared to heavy cars (0.0303), indicating that newer models of lighter cars have improved more in fuel efficiency over time than heavier cars.

3. The `acceleration` variable has a positive effect on `mpg`, but it is only statistically significant for light cars (p-value = 0.0578). This means that faster acceleration tends to be associated with better fuel efficiency for light cars, while the relationship is not statistically significant for heavy cars.

4. The `origin` variable shows a significant positive effect on `mpg` for heavy cars (p-value = 0.0246) but not for light cars (p-value = 0.1698). This suggests that the origin of heavy cars has a more substantial impact on fuel efficiency compared to light cars.

Overall, the results indicate that both light and heavy cars share some similarities in the factors affecting their fuel efficiency (mpg). However, there are differences in the magnitude and statistical significance of these factors, suggesting that the dynamics of fuel efficiency might vary between light and heavy cars.


### Question 2) Use the transformed dataset from above (cars_log), to test whether we have moderation.

### a. (not graded) Considering weight and acceleration, use your intuition and experience to state which of the two variables might be a moderating versus independent variable, in affecting mileage. 

Based on the transformed dataset (cars_log) and considering weight and acceleration as potential factors affecting mileage (mpg), it is reasonable to hypothesize that:

1. Weight might be a moderating variable: The relationship between acceleration and mileage (mpg) could be different for light-weight and heavy cars. In other words, the effect of acceleration on mpg might be stronger or weaker depending on the weight of the car.

2. Acceleration would be an independent variable: Acceleration is directly related to how the car performs and is likely to have a direct impact on the car's fuel efficiency (mpg) without necessarily depending on the weight of the car.

this is a hypothesis based on intuition and experience, and it should be tested statistically to validate or refute the assumptions.

### b. Use various regression models to model the possible moderation on log.mpg.:(use log.weight., log.acceleration., model_year and origin as independent variables)

### i. Report a regression without any interaction terms

```{r}
model1 <- lm(mpg ~ weight + acceleration + model_year + origin, data = cars_log)
summary(model1)

```

### ii. Report a regression with an interaction between weight and acceleration


```{r}
model2 <- lm(mpg ~ weight * acceleration + model_year + origin, data = cars_log)
summary(model2)

```

### iii. Report a regression with a mean-centered interaction term


```{r}
# Mean-center weight and acceleration
cars_log$centered_weight <- cars_log$weight - mean(cars_log$weight)
cars_log$centered_acceleration <- cars_log$acceleration - mean(cars_log$acceleration)

model3 <- lm(mpg ~ centered_weight * centered_acceleration + model_year + origin, data = cars_log)
summary(model3)

```

### iv. Report a regression with an orthogonalized interaction term


```{r}
# Orthogonalize weight and acceleration
cars_log$orth_weight <- cars_log$weight - cor(cars_log$weight, cars_log$acceleration) * cars_log$acceleration

model4 <- lm(mpg ~ orth_weight * acceleration + model_year + origin, data = cars_log)
summary(model4)

```
### c. For each of the interaction term strategies above (raw, mean-centered, orthogonalized) what is the correlation between that interaction term and the two variables that you multiplied together?

1. Raw interaction term (weight * acceleration):

```{r}
cor(cars_log$weight, cars_log$weight * cars_log$acceleration)
cor(cars_log$acceleration, cars_log$weight * cars_log$acceleration)

```
2. Mean-centered interaction term (centered_weight * centered_acceleration):

```{r}
cor(cars_log$centered_weight, cars_log$centered_weight * cars_log$centered_acceleration)
cor(cars_log$centered_acceleration, cars_log$centered_weight * cars_log$centered_acceleration)

```
3. Orthogonalized interaction term (orth_weight * acceleration):

```{r}
cor(cars_log$orth_weight, cars_log$orth_weight * cars_log$acceleration)
cor(cars_log$acceleration, cars_log$orth_weight * cars_log$acceleration)

```

### Question 3) We saw earlier that the number of cylinders does not seem to directly influence mpg when car weight is also considered.  But might cylinders have an indirect relationship with mpg through its weight? 

### Let’s check whether weight mediates the relationship between cylinders and mpg, even when other factors are controlled for.  Use log.mpg., log.weight., and log.cylinders as your main variables, and keep log.acceleration., model_year, and origin as control variables (see gray variables in diagram).


### a. Let’s try computing the direct effects first:

### i. Model 1: Regress log.weight. over log.cylinders. only (check whether number of cylinders has a significant direct effect on weight)

```{r}
model1_direct <- lm(weight ~ cylinders, data = cars_log)
summary(model1_direct)

```

### ii. Model 2: Regress log.mpg. over log.weight. and all control variables (check whether weight has a significant direct effect on mpg with other variables statistically controlled)

```{r}
model2_direct <- lm(mpg ~ weight + acceleration + model_year + origin, data = cars_log)
summary(model2_direct)

```

### b. What is the indirect effect of cylinders on mpg? (use the product of slopes between Models 1 & 2)

Model 1: log.weight ~ log.cylinders
Coefficient (slope) for log.cylinders: 0.145544

Model 2: log.mpg ~ log.weight + log.acceleration + model_year + origin
Coefficient (slope) for log.weight: -0.889384

Indirect effect = (slope of log.cylinders in Model 1) * (slope of log.weight in Model 2) = 0.145544 * (-0.889384) = -0.129479

The indirect effect of log.cylinders on log.mpg through log.weight is -0.129479. 

This indicates that as the number of cylinders increases, the mpg decreases indirectly through the effect of increased weight.

### c. Let’s bootstrap for the confidence interval of the indirect effect of cylinders on mpg

### i. Bootstrap regression models 1 & 2, and compute the indirect effect each time: What is its 95% CI of the indirect effect of log.cylinders. on log.mpg.?

```{r}
library(boot)

# Define function to compute indirect effects
indirect_effect <- function(data, indices) {
  data <- data[indices,]
  
  model1 <- lm(weight ~ cylinders, data = data)
  model2 <- lm(mpg ~ weight + acceleration + model_year + origin, data = data)
  
  indirect <- coef(model1)["cylinders"] * coef(model2)["weight"]
  
  return(indirect)
}

set.seed(12345)  # You can choose any number as the seed
#Boot strapped for 10000 times 
boot_results <- boot(data = cars_log, statistic = indirect_effect, R = 10000)

# Compute 95% CI
boot_ci <- boot.ci(boot.out = boot_results, conf = 0.95, type = "perc")
boot_ci
```

The 95% confidence interval using the percentile method is given as (-0.1402, -0.1190). This means that we can be 95% confident that the true value of the statistic falls within this interval. Note that this is an estimate, and the true value may still fall outside this range. 


### ii. Show a density plot of the distribution of the 95% CI of the indirect effect

```{r}
#extracts the indirect effect 
indirect_effects <- boot_results$t
# Create a density plot of the indirect effects
ggplot(data.frame(indirect_effects), aes(x=indirect_effects)) +
  geom_density(fill="blue", alpha=0.5) +
  geom_vline(aes(xintercept=-0.1402), color="red", linetype="dashed") +
  geom_vline(aes(xintercept=-0.1190), color="red", linetype="dashed") +
  labs(title="Density Plot of the 95% CI of the Indirect Effect",
       x="Indirect Effect",
       y="Density") +
  theme_minimal()

```

